input {
    # tcp {
    #     port => 5000
    #     codec => json   # Se espera recibir logs en formato JSON
    # }
    kafka {
        bootstrap_servers => "kafka:9092"
        topics => ["gestfy-logs"]
        group_id => "logstash-gestfy" # Identificador del grupo de consumidores
        codec => json
        consumer_threads => 4 # Utiliza 4 threads para consumir en paralelo (uno por partición)
        # Configura parámetros óptimos para procesar logs en lotes grandes
        max_poll_records => 500
        max_poll_interval_ms => 300000
        fetch_max_bytes => "10485760"
        # batch_size => 1000
        # auto_offset_reset => "earliest" # Al arrancar comienza a leer desde el inicio del topic
        auto_offset_reset => "latest"
    }
}

# Agregar filtros aquí si se necesita transformar o enriquecer los logs
filter {

}

output {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "logstash-%{+YYYY.MM.dd}"
        user => "elastic"
        password => "Password1!"
    }
    stdout { codec => rubydebug }  # Permite imprimir en consola los logs procesados
}
